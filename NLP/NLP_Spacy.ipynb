{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled25.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utuyyz6hVGFr",
        "colab_type": "text"
      },
      "source": [
        "# **NLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mwUPkuj3n0N",
        "colab_type": "text"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgGR_GU5VI06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "text = \"\"\"When learning Artificial Intelligence, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "\n",
        "my_doc = nlp(text)\n",
        "print (\"Document format ----> \", my_doc)\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "\ttoken_list.append(token.text)\n",
        "print(\"List Format ----> \",token_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgRfCcX1VpwH",
        "colab_type": "text"
      },
      "source": [
        "# **Sentencizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAB4PYnRWZA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "sbd = nlp.create_pipe('sentencizer')\n",
        "\n",
        "nlp.add_pipe(sbd)\n",
        "\n",
        "text = \"\"\"When learning Artificial Intelligence, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "sents_list = []\n",
        "for sent in doc.sents:\n",
        "    sents_list.append(sent.text)\n",
        "print(sents_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rD4-pLuW0Fh",
        "colab_type": "text"
      },
      "source": [
        "### **Stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y-ZEi_7XG9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "spacy_stopwords = STOP_WORDS\n",
        "\n",
        "\n",
        "print('Number of stop words: %d' % len(spacy_stopwords))\n",
        "\n",
        "\n",
        "print('First ten stop words: %s' % list(spacy_stopwords)[:10])\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "\n",
        "text = \"\"\"When learning Artificial Intelligence, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "\n",
        "filtered_sent=[]\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for word in doc:\n",
        "    if word.is_stop==False:\n",
        "        filtered_sent.append(word)\n",
        "print(\"Filtered Sentence:\",filtered_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdG2goFfXgYu",
        "colab_type": "text"
      },
      "source": [
        "# **lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smc3BWH6X-lH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "lem = nlp(\"run runs running runner\")\n",
        "\n",
        "\n",
        "\n",
        "for word in lem:\n",
        "    print(word.text,word.lemma_)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO2P_jm5Y-vC",
        "colab_type": "text"
      },
      "source": [
        "# **parts of speech**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psmBE3D8ZRno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import en_core_web_sm\n",
        "\n",
        "\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "docs = nlp(u\"All is well that ends well.\")\n",
        "\n",
        "for word in docs:\n",
        "    print(word.text,word.pos_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw21QAU7ZgK_",
        "colab_type": "text"
      },
      "source": [
        "# **Dependency parasing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rvq7nB9Z2IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "import en_core_web_sm\n",
        "\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "docp = nlp (\" In pursuit of a wall, President Trump ran into one.\")\n",
        "\n",
        "for chunk in docp.noun_chunks:\n",
        "   print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
        "          chunk.root.head.text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxXd0atEaCG2",
        "colab_type": "text"
      },
      "source": [
        "# **Word vector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxe4rTzjaNlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "mango = nlp(u'mango')\n",
        "\n",
        "print(mango.vector.shape)\n",
        "print(mango.vector)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}